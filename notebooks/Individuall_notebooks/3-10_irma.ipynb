{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dc16450-eafe-4c8b-b91c-f2357b240111",
   "metadata": {},
   "source": [
    "## Setup and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb373cf-aba1-4e0d-a803-54b823052b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Setup: libraries and config ===\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "\n",
    "# Load config.yaml\n",
    "try:\n",
    "    with open(\"../config.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    print(\"Config loaded successfully\")\n",
    "except Exception as e:\n",
    "    raise FileNotFoundError(\"config.yaml not found at ../config.yaml\") from e\n",
    "\n",
    "print(\"Top-level keys:\", list(config.keys()))\n",
    "\n",
    "# === Load clean dataframe (df_full) ===\n",
    "clean_cfg = config.get(\"data\", {}).get(\"clean\", {})\n",
    "if \"df_full\" not in clean_cfg:\n",
    "    raise KeyError(\"'df_full' no est√° definido en config['data']['clean']\")\n",
    "\n",
    "path = Path(clean_cfg[\"df_full\"])\n",
    "if not path.exists():\n",
    "    raise FileNotFoundError(f\"No encuentro el archivo en: {path}\")\n",
    "\n",
    "df_full = pd.read_pickle(path)\n",
    "print(f\" df_full loaded successfully: {df_full.shape}\")\n",
    "display(df_full.head())\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ca6552-3e84-48cd-81ce-6b8ab4c7a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Check columns, types and null values (df_full) ===\n",
    "\n",
    "print(\"df_full shape:\", df_full.shape)\n",
    "\n",
    "print(\"\\nFirst 2 rows:\")\n",
    "display(df_full.head(2))\n",
    "\n",
    "print(\"\\nInfo:\")\n",
    "print(df_full.info())\n",
    "\n",
    "print(\"\\nMissing values per column (first 10 shown):\")\n",
    "print(df_full.isna().sum().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80146d-aa6e-4836-ad6d-167a7d674d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_web = df_full.copy()\n",
    "print(df_web.shape)\n",
    "df_web.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6585840f-5a22-49c6-bbba-6d009c628b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc49ffd7-c714-4079-9168-3816d3d0762f",
   "metadata": {},
   "source": [
    "## Exploratory Analysis ‚Äì Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27135de8-0781-47a2-aeca-abcbe3fcf282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Age distribution\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(df_full[\"clnt_age\"].dropna(), bins=30, kde=True, color=\"steelblue\")\n",
    "plt.title(\"Client Age Distribution\", fontsize=14)\n",
    "plt.xlabel(\"Age (years)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Gender distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(\n",
    "    x=\"gendr\", \n",
    "    hue=\"gendr\",  \n",
    "    data=df_full, \n",
    "    order=df_full[\"gendr\"].value_counts().index, \n",
    "    palette=\"Set2\", \n",
    "    legend=False   \n",
    ")\n",
    "plt.title(\"Gender Distribution\", fontsize=14)\n",
    "plt.xlabel(\"Gender\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Tenure in years\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(df_full[\"clnt_tenure_yr\"].dropna(), bins=30, kde=True, color=\"darkgreen\")\n",
    "plt.title(\"Client Tenure (years)\", fontsize=14)\n",
    "plt.xlabel(\"Years with Vanguard\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Balance distribution (log scale to handle skewness)\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(x=np.log1p(df_full[\"bal\"].dropna()), color=\"darkred\")\n",
    "plt.title(\"Client Balance Distribution (log scale)\", fontsize=14)\n",
    "plt.xlabel(\"Log(1 + Balance)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960130d5-8fc8-416d-9f2d-eaaeafe730da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge demographics + variation at client level (adaptado a df_full)\n",
    "demo_var = df_full.copy()\n",
    "\n",
    "# Tidy categories\n",
    "demo_var[\"Variation\"] = demo_var[\"Variation\"].fillna(\"Non-Experiment\")\n",
    "demo_var[\"gendr\"] = demo_var[\"gendr\"].fillna(\"Unknown\")\n",
    "\n",
    "# (Opcional) ordena categor√≠as para consistencia visual\n",
    "gendr_order = demo_var[\"gendr\"].value_counts().index.tolist()  # p.ej., ['U','M','F'] o similar\n",
    "var_order = [\"Control\", \"Test\", \"Non-Experiment\"]  # mostrar√° las que existan en el df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e7d0b1-5462-4ee5-b30b-2603cac92e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.countplot(\n",
    "    data=demo_var,\n",
    "    x=\"gendr\",\n",
    "    hue=\"Variation\",     \n",
    "    order=gendr_order,\n",
    "    hue_order=[v for v in var_order if v in demo_var[\"Variation\"].unique()],\n",
    "    palette=\"Set2\"\n",
    ")\n",
    "plt.title(\"Gender distribution by variation\", fontsize=14)\n",
    "plt.xlabel(\"Gender\"); plt.ylabel(\"Number of clients\")\n",
    "plt.legend(title=\"Variation\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b30464-18a6-4255-bd1a-efc65614ba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographics overview WITH variation (Control / Test / Non-Experiment)\n",
    "demo_var = df_full.copy()\n",
    "\n",
    "# Normalizar columna de Variation (ya viene en df_full)\n",
    "if \"Variation\" in demo_var.columns:\n",
    "    demo_var = demo_var.rename(columns={\"Variation\": \"variation\"})\n",
    "\n",
    "# Fill NaN = Non-Experiment\n",
    "demo_var[\"variation\"] = demo_var[\"variation\"].fillna(\"Non-Experiment\")\n",
    "\n",
    "# Conteo de clientes por grupo\n",
    "print(demo_var[\"variation\"].value_counts())\n",
    "\n",
    "# Summaries by variation group\n",
    "for group, subset in demo_var.groupby(\"variation\"):\n",
    "    print(f\"\\n===== {group} =====\")\n",
    "    print(\"Age summary:\\n\", subset[\"clnt_age\"].describe())\n",
    "    print(\"\\nGender distribution:\\n\", subset[\"gendr\"].value_counts(dropna=False))\n",
    "    print(\"\\nTenure (years) summary:\\n\", subset[\"clnt_tenure_yr\"].describe())\n",
    "    print(\"\\nBalance summary:\\n\", subset[\"bal\"].describe())\n",
    "    print(\"\\n-----------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579c4453-d86e-446e-b536-fb764df81f65",
   "metadata": {},
   "source": [
    "##### Day 2 ‚Äì Demographic Analysis  \n",
    "\n",
    "We explored the cleaned client dataset (`df_full`) to better understand who the primary users of Vanguard‚Äôs online process are.  \n",
    "This analysis distinguishes between **Control**, **Test**, and **Non-Experiment** clients.  \n",
    "\n",
    "### Age  \n",
    "- Overall average age ~46 (median 47).  \n",
    "- **Non-Experiment** clients are slightly younger (mean ~45).  \n",
    "- **Control** and **Test** clients average ~48.  \n",
    "üëâ The experiment seems to target slightly older clients compared to those not included.  \n",
    "\n",
    "### Gender  \n",
    "- Nearly balanced between Male and Female in the experiment groups.  \n",
    "- A very large portion of **Non-Experiment** clients are labeled as ‚ÄúUnknown‚Äù (~70%).  \n",
    "- Control and Test groups also include ~34% ‚ÄúUnknown‚Äù.  \n",
    "üëâ Gender classification has major data quality gaps, especially for Non-Experiment clients.  \n",
    "\n",
    "### Tenure (Years with Vanguard)  \n",
    "- Average ~12 years, median ~11, range 2‚Äì62.  \n",
    "- Distributions are very similar across all groups.  \n",
    "üëâ Clients are typically long-standing; experiment assignment does not depend on tenure.  \n",
    "\n",
    "### Balances  \n",
    "- Overall mean balance ~150k, median ~63k.  \n",
    "- **Control/Test** participants show slightly higher average balances ~159k‚Äì164k compared to **Non-Experiment** ~153k.  \n",
    "- Distribution is strongly skewed: most clients hold moderate balances (<140k), while a wealthy minority drives the average up.  \n",
    "\n",
    "---\n",
    "\n",
    "### Answers to Day 2 Questions  \n",
    "**Who are the primary clients?**  \n",
    "Middle-aged investors (30‚Äì60 years), balanced between male and female (when data is available), long-standing ~10+ years, with moderate balances.  \n",
    "\n",
    "**Are they younger or older, new or long-standing?**  \n",
    "They are generally older and long-standing clients. The experiment slightly favors older clients with somewhat higher balances compared to those not included.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1e57b7-b76b-47e9-a4d5-df878898abb0",
   "metadata": {},
   "source": [
    "## Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eea0f42-5339-4142-ab95-b072a7a34fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers - Balance\n",
    "Q1 = df_full[\"bal\"].quantile(0.25)\n",
    "Q3 = df_full[\"bal\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = df_full[(df_full[\"bal\"] < lower_bound) | (df_full[\"bal\"] > upper_bound)]\n",
    "print(\"Number of outliers in balance:\", outliers.shape[0])\n",
    "print(\"Outlier values summary:\\n\", outliers[\"bal\"].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b24a365-27cd-42c0-a683-4182128f4b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers - Age\n",
    "Q1 = df_full[\"clnt_age\"].quantile(0.25)\n",
    "Q3 = df_full[\"clnt_age\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers_age = df_full[(df_full[\"clnt_age\"] < lower_bound) | (df_full[\"clnt_age\"] > upper_bound)]\n",
    "print(\"Number of outliers in age:\", outliers_age.shape[0])\n",
    "print(\"Outlier values summary:\\n\", outliers_age[\"clnt_age\"].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8425d08a-fb16-4ee0-b5b3-4f557b2e1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers - Tenure (years)\n",
    "Q1 = df_full[\"clnt_tenure_yr\"].quantile(0.25)\n",
    "Q3 = df_full[\"clnt_tenure_yr\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers_tenure = df_full[(df_full[\"clnt_tenure_yr\"] < lower_bound) | (df_full[\"clnt_tenure_yr\"] > upper_bound)]\n",
    "print(\"Number of outliers in tenure (years):\", outliers_tenure.shape[0])\n",
    "print(\"Outlier values summary:\\n\", outliers_tenure[\"clnt_tenure_yr\"].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e587c50-5d93-4e18-beb7-a63addc70ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers - Number of accounts\n",
    "Q1 = df_full[\"num_accts\"].quantile(0.25)\n",
    "Q3 = df_full[\"num_accts\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers_accts = df_full[(df_full[\"num_accts\"] < lower_bound) | (df_full[\"num_accts\"] > upper_bound)]\n",
    "print(\"Number of outliers in number of accounts:\", outliers_accts.shape[0])\n",
    "print(\"Outlier values summary:\\n\", outliers_accts[\"num_accts\"].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5851429-3b11-472b-a1d6-75eb99a3f6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\"clnt_age\", \"clnt_tenure_yr\", \"num_accts\", \"bal\"]\n",
    "\n",
    "for var in variables:\n",
    "    print(f\"\\n### Outlier analysis for {var}\")\n",
    "    for group, subset in demo_var.groupby(\"variation\"):\n",
    "        Q1 = subset[var].quantile(0.25)\n",
    "        Q3 = subset[var].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        outliers = subset[(subset[var] < lower_bound) | (subset[var] > upper_bound)]\n",
    "\n",
    "        print(f\"\\n===== {group} =====\")\n",
    "        print(f\"Number of outliers in {var}: {outliers.shape[0]}\")\n",
    "        print(f\"Outlier values summary:\\n{outliers[var].describe()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2218da75-1f0d-477c-9b56-f15e543ac087",
   "metadata": {},
   "source": [
    "##### Outlier Analysis  \n",
    "\n",
    "We applied the Interquartile Range (IQR) method to detect statistical outliers across age, tenure, number of accounts, and balances, separated by **Control**, **Test**, and **Non-Experiment** groups.  \n",
    "\n",
    "### Age (`clnt_age`)  \n",
    "- No outliers detected in any group.  \n",
    "- Age distribution is realistic, mostly between 30 and 60 years.  \n",
    "üëâ This suggests strong data quality for age with no anomalies.  \n",
    "\n",
    "### Tenure (`clnt_tenure_yr`)  \n",
    "- Control: **1,793** outliers  \n",
    "- Non-Experiment: **2,013** outliers  \n",
    "- Test: **2,421** outliers  \n",
    "- These correspond to clients with 32‚Äì62 years of tenure.  \n",
    "üëâ Test group contains more very long-standing clients, but overall these cases remain a small minority.  \n",
    "\n",
    "### Number of Accounts (`num_accts`)  \n",
    "- Control: **32,716** outliers  \n",
    "- Non-Experiment: **28,891** outliers  \n",
    "- Test: **37,931** outliers  \n",
    "- Most clients hold 2‚Äì3 accounts, but some have 6‚Äì8 accounts, which the IQR method flags as unusual.  \n",
    "üëâ Outliers appear in all groups at similar proportions, reflecting clients with more complex account structures rather than errors.  \n",
    "\n",
    "### Balances (`bal`)  \n",
    "- Control: **16,532** outliers  \n",
    "- Non-Experiment: **14,549** outliers  \n",
    "- Test: **19,950** outliers  \n",
    "- Outliers average ~730k‚Äì780k, with maxima up to **8.3M** (Control), **12.8M** (Non-Experiment), and **16.3M** (Test).  \n",
    "üëâ Confirms a consistent high-wealth client segment across all groups, not concentrated in a single variation.  \n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion  \n",
    "- **Balances** are the most skewed variable, with ~51k clients holding exceptionally high wealth.  \n",
    "- **Tenure** and **Number of Accounts** also show minority extremes, representing very long-standing or complex clients.  \n",
    "- **Age** shows no anomalies.  \n",
    "- Importantly, outlier patterns are consistent across **Control**, **Test**, and **Non-Experiment**, meaning they do not bias the experiment‚Äôs comparison of completion rates or performance metrics.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabadbe6-5fcf-46b4-8943-590e7db3905b",
   "metadata": {},
   "source": [
    "### Mean Completion Time per Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f15ab6-0083-40b2-8841-acc1c3773cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Sort visits properly \n",
    "\n",
    "df_full = df_full.sort_values([\"visit_id\", \"date_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703714ec-6280-4409-b8c0-c70d7e8bc3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Sort visits properly\n",
    "\n",
    "df_full = df_full.sort_values([\"visit_id\", \"date_time\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f8960-d50e-4939-8700-89e767c166f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Map process steps into numeric order\n",
    "step_order = {\"step 1\":1, \"step 2\":2, \"step 3\":3, \"confirm\":4}\n",
    "df_full[\"step_order\"] = df_full[\"process_step\"].map(step_order)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f67bb-6ff9-4d23-9703-b13e58748b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Compute time differences per visit\n",
    "df_full[\"time_diff\"] = df_full.groupby(\"visit_id\")[\"date_time\"].diff()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beadbc4-4dc8-4740-b829-89088422464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Aggregate mean time per step and variation\n",
    "mean_times = (\n",
    "    df_full.groupby([\"Variation\", \"process_step\"])[\"time_diff\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Convert to seconds (optional)\n",
    "mean_times[\"time_diff_sec\"] = mean_times[\"time_diff\"].dt.total_seconds()\n",
    "\n",
    "print(mean_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dda626-1262-426e-a6f7-e4941cd297db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=mean_times, x=\"process_step\", y=\"time_diff_sec\", hue=\"Variation\")\n",
    "plt.ylabel(\"Mean Time (seconds)\")\n",
    "plt.title(\"Mean Completion Time per Step: Control vs Test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95159589-a328-4b13-a742-b747dc0f5d11",
   "metadata": {},
   "source": [
    "### Mean Completion Time per Step ‚Äì Analysis  \n",
    "\n",
    "We calculated the **average time spent on each step** of the process by both the Control and Test groups. Results (in seconds) are as follows:\n",
    "\n",
    "| Step       | Control (sec) | Test (sec) | Observation |\n",
    "|------------|---------------|------------|-------------|\n",
    "| Start      | ~154.9        | ~148.9     | Test clients move slightly faster through the initial step, saving ~6 seconds. |\n",
    "| Step 1     | ~43.0         | ~37.7      | Both groups complete this step quickly, but Test is faster by ~5 seconds. |\n",
    "| Step 2     | ~38.7         | ~48.1      | The Test group takes ~9 seconds longer than Control, suggesting the redesign may add friction here. |\n",
    "| Step 3     | ~92.9         | ~96.9      | Both groups spend similar time, with Test slightly slower (~4 seconds). |\n",
    "| Confirm    | ~128.5        | ~129.2     | No meaningful difference at confirmation. |\n",
    "\n",
    "---\n",
    "\n",
    "#### Insights:\n",
    "- ‚úÖ **Faster start and Step 1:** Test clients progress more quickly at the beginning, suggesting the new interface helps initial orientation.  \n",
    "- ‚ö†Ô∏è **Step 2 slowdown:** Test group spends ~9 seconds longer, which may indicate **confusion** or **extra cognitive load** introduced by the redesign.  \n",
    "- ‚öñÔ∏è **Step 3 and Confirm:** Differences are minimal; performance is nearly identical between groups.  \n",
    "- üîÑ **Overall pattern:** Improvements early in the process (Start, Step 1) are offset by a slowdown in Step 2.  \n",
    "\n",
    "---\n",
    "\n",
    "#### Next Steps:\n",
    "- Compare these per-step averages with **step completion/drop-off rates** to see if the Step 2 slowdown impacts conversion.  \n",
    "- Conduct a **qualitative review of Step 2** in the Test interface to identify potential friction points.  \n",
    "- Extend the analysis to **total completion time** (Start ‚Üí Confirm) for a holistic view of efficiency.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafe6b36-d1e7-4fcd-a85f-5929915c397f",
   "metadata": {},
   "source": [
    "### Mean Completion Time (Start-Confirm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f947114-d299-4eed-ba4d-ec0179063a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work only with experiment participants\n",
    "df_exp = df_full[df_full[\"Variation\"].isin([\"Control\",\"Test\"])].copy()\n",
    "\n",
    "# Ensure datetime is correct and sorted\n",
    "df_exp[\"date_time\"] = pd.to_datetime(df_exp[\"date_time\"])\n",
    "df_exp = df_exp.sort_values([\"visit_id\", \"date_time\"])\n",
    "\n",
    "# Get first and last timestamp per visit (only if they reached confirm)\n",
    "visit_times = (\n",
    "    df_exp.groupby([\"Variation\",\"visit_id\"])\n",
    "          .agg(start_time=(\"date_time\",\"first\"),\n",
    "               end_time=(\"date_time\",\"last\"))\n",
    "          .reset_index()\n",
    ")\n",
    "\n",
    "# Calculate duration\n",
    "visit_times[\"completion_time\"] = (visit_times[\"end_time\"] - visit_times[\"start_time\"]).dt.total_seconds()\n",
    "\n",
    "# Keep only visits that actually reached \"confirm\"\n",
    "completed_visits = df_exp[df_exp[\"process_step\"]==\"confirm\"][\"visit_id\"].unique()\n",
    "visit_times = visit_times[visit_times[\"visit_id\"].isin(completed_visits)]\n",
    "\n",
    "# Mean completion time per group\n",
    "mean_completion = visit_times.groupby(\"Variation\")[\"completion_time\"].mean().round(2)\n",
    "print(\"Mean completion time (seconds):\")\n",
    "print(mean_completion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9746d0-ba43-4290-918a-21548a348296",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_completion / 60)  # mean in minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d44668-8e91-4c61-81ed-19a866290f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert to DataFrame for seaborn\n",
    "mean_df = mean_completion.reset_index()\n",
    "mean_df.columns = [\"variation\", \"completion_time\"]\n",
    "\n",
    "sns.barplot(data=mean_df, x=\"variation\", y=\"completion_time\", hue=\"variation\", palette=\"Set2\", legend=False)\n",
    "plt.ylabel(\"Mean Completion Time (seconds)\")\n",
    "plt.title(\"Mean Completion Time: Control vs Test\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90c2613-f7bd-41f3-988b-8e245a78c415",
   "metadata": {},
   "source": [
    "##### ‚è± Mean Completion Time (Start ‚Üí Confirm)  \n",
    "\n",
    "We calculated the **average completion time** from the initial step (`start`) to the final confirmation (`confirm`) for both groups.  \n",
    "\n",
    "### Results  \n",
    "- **Control group**: ~394 seconds (‚âà **6.56 minutes**)  \n",
    "- **Test group**: ~362 seconds (‚âà **6.04 minutes**)  \n",
    "\n",
    "### Insights  \n",
    "- On average, clients in the **Test group completed the full process ~32 seconds faster** than those in the Control group.  \n",
    "- While the difference is modest, it suggests that the redesigned interface **improves overall efficiency**.  \n",
    "- However, further statistical testing is needed to confirm whether this observed difference is **statistically significant** or due to random variation.  \n",
    "\n",
    "### Next Steps  \n",
    "To further validate our findings, we will:  \n",
    "\n",
    "1. **Select random clients from each group (Control & Test):**  \n",
    "   - Pick 3 clients per group.  \n",
    "   - Compute their individual completion times from **Start ‚Üí Confirm**.  \n",
    "\n",
    "2. **Run a Two-Sample T-Test:**  \n",
    "   - Compare the average completion times between Control and Test groups.  \n",
    "   - Hypotheses:  \n",
    "     - **H0 (Null):** There is no difference in mean completion time between groups.  \n",
    "     - **H1 (Alternative):** The Test group has a significantly different mean completion time compared to Control.  \n",
    "\n",
    "3. **Interpret results:**  \n",
    "   - A **p-value < 0.05** will indicate a significant difference.  \n",
    "   - If not, the new design did not significantly change the completion time.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c873c16-78fb-4a92-9989-b6b286f2f179",
   "metadata": {},
   "source": [
    "## Sample Client Journey Analysis‚ÄìControl vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfcc459-56f0-4fc0-9d59-75183fbe78a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only experiment participants (Control and Test)\n",
    "df_exp = df_full[df_full[\"Variation\"].isin([\"Control\",\"Test\"])].copy()\n",
    "\n",
    "# Sort by visit and ensure datetime format\n",
    "df_exp = df_exp.sort_values([\"visit_id\",\"date_time\"]).copy()\n",
    "df_exp[\"date_time\"] = pd.to_datetime(df_exp[\"date_time\"], errors=\"coerce\")\n",
    "\n",
    "print(df_exp[\"Variation\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d74e3a7-c568-459b-b8dd-0da004fd090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sample of 3 clients from each group (Control and Test)\n",
    "sample_clients = (\n",
    "    df_exp.groupby(\"Variation\")[\"client_id\"]\n",
    "          .apply(lambda x: x.dropna().sample(3, random_state=42))\n",
    "          .reset_index()\n",
    ")\n",
    "\n",
    "print(\"Random sample of clients:\\n\", sample_clients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82be662-7b2e-418f-a25a-a7308f0a5154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df_exp for only these client_ids\n",
    "df_sample = df_exp[df_exp[\"client_id\"].isin(sample_clients[\"client_id\"])]\n",
    "\n",
    "# Check each client‚Äôs process\n",
    "for cid in sample_clients[\"client_id\"]:\n",
    "    print(f\"\\n=== Client {cid} ===\")\n",
    "    print(df_sample[df_sample[\"client_id\"] == cid][[\"Variation\",\"visit_id\",\"process_step\",\"date_time\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49aa33-0559-461b-b4f0-8fd82c299f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Make sure we‚Äôre on experiment participants only\n",
    "# Keep only Control/Test participants\n",
    "df_exp = df_full[df_full[\"Variation\"].isin([\"Control\",\"Test\"])].copy()\n",
    "\n",
    "# Ensure sorted + datetime\n",
    "df_exp = df_exp.sort_values([\"visit_id\",\"date_time\"]).copy()\n",
    "df_exp[\"date_time\"] = pd.to_datetime(df_exp[\"date_time\"], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f098e-7c49-4742-a6ff-8804bd385e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Pick 3 random clients per group\n",
    "sampled = (\n",
    "    df_exp.groupby(\"Variation\")[\"client_id\"]\n",
    "          .apply(lambda s: s.dropna().drop_duplicates().sample(3, random_state=42))\n",
    "          .reset_index()\n",
    "          .rename(columns={\"client_id\":\"client_id\"})\n",
    ")\n",
    "sample_client_ids = sampled[\"client_id\"].tolist()\n",
    "print(\"Sampled client_ids:\", sample_client_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada7dc72-06fb-4e77-b091-79b80351b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) Keep only those clients and choose one visit per client\n",
    "df_s = df_exp[df_exp[\"client_id\"].isin(sample_client_ids)].copy()\n",
    "\n",
    "# For each client/visit: did it reach confirm? what's the last timestamp?\n",
    "vis_stats = (df_s.assign(has_confirm=(df_s[\"process_step\"].str.lower()==\"confirm\"))\n",
    "               .groupby([\"client_id\",\"visit_id\"])\n",
    "               .agg(last_time=(\"date_time\",\"max\"), reached_confirm=(\"has_confirm\",\"max\"))\n",
    "               .reset_index())\n",
    "\n",
    "# Choose per client: prioritize (reached_confirm=True), then by latest time\n",
    "choice = (vis_stats.sort_values([\"client_id\",\"reached_confirm\",\"last_time\"])\n",
    "                   .groupby(\"client_id\")\n",
    "                   .tail(1)[[\"client_id\",\"visit_id\"]])\n",
    "\n",
    "# Keep only the chosen visit per client\n",
    "df_s = df_s.merge(choice, on=[\"client_id\",\"visit_id\"], how=\"inner\").copy()\n",
    "df_s = df_s.sort_values([\"client_id\",\"visit_id\",\"date_time\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2626e3-385f-4bfb-9fd6-9f7e5f99ba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) Compute per-step durations (no apply, no warnings)\n",
    "# Duration until the next step within each visit\n",
    "df_s[\"next_time\"] = df_s.groupby([\"client_id\",\"visit_id\"])[\"date_time\"].shift(-1)\n",
    "df_s[\"step_duration\"] = (df_s[\"next_time\"] - df_s[\"date_time\"]).dt.total_seconds()\n",
    "\n",
    "# Seconds from visit start (for left offset on the timeline)\n",
    "df_s[\"visit_t0\"] = df_s.groupby([\"client_id\",\"visit_id\"])[\"date_time\"].transform(\"min\")\n",
    "df_s[\"t_rel\"] = (df_s[\"date_time\"] - df_s[\"visit_t0\"]).dt.total_seconds()\n",
    "\n",
    "# Drop the last row of each visit (no duration after the final step)\n",
    "df_steps = df_s.dropna(subset=[\"step_duration\"]).copy()\n",
    "df_steps.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9421f0a7-c611-45fb-9ada-2a0ad804ad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Keep only experiment participants\n",
    "df_exp = df_full[df_full[\"Variation\"].isin([\"Control\",\"Test\"])].copy()\n",
    "\n",
    "# Normalize steps + datetime + sort\n",
    "df_exp[\"process_step\"] = (\n",
    "    df_exp[\"process_step\"].astype(str).str.strip().str.lower()\n",
    "      .replace({\"step1\":\"step 1\",\"step_1\":\"step 1\",\n",
    "                \"step2\":\"step 2\",\"step_2\":\"step 2\",\n",
    "                \"step3\":\"step 3\",\"step_3\":\"step 3\",\n",
    "                \"confirmation\":\"confirm\"})\n",
    ")\n",
    "df_exp[\"date_time\"] = pd.to_datetime(df_exp[\"date_time\"], errors=\"coerce\")\n",
    "df_exp = df_exp.sort_values([\"visit_id\",\"date_time\"])\n",
    "\n",
    "# Standard step order (use only those present in your data)\n",
    "all_steps = [\"start\",\"step 1\",\"step 2\",\"step 3\",\"confirm\"]\n",
    "steps = [s for s in all_steps if s in df_exp[\"process_step\"].unique()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f032508f-9dde-4330-a7a3-296d0bc8526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funnel_counts(df, steps):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with counts of unique visits that reached each step,\n",
    "    for every variation (Control/Test).\n",
    "    \"\"\"\n",
    "    # Has step? -> per visit\n",
    "    has_step = (df.drop_duplicates([\"visit_id\",\"process_step\"])\n",
    "                  .groupby([\"Variation\",\"process_step\"])[\"visit_id\"]\n",
    "                  .nunique()\n",
    "                  .rename(\"visits\")\n",
    "                  .reset_index())\n",
    "\n",
    "    # Ensure all steps appear per variation (fill 0 if missing)\n",
    "    variations = has_step[\"Variation\"].unique().tolist()\n",
    "    idx = pd.MultiIndex.from_product([variations, steps], names=[\"Variation\",\"process_step\"])\n",
    "    has_step = has_step.set_index([\"Variation\",\"process_step\"]).reindex(idx, fill_value=0).reset_index()\n",
    "    return has_step\n",
    "\n",
    "funnel_df = funnel_counts(df_exp, steps)\n",
    "funnel_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a42d1ed-eba1-4626-9d67-55b62909c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = (funnel_df.pivot(index=\"Variation\", columns=\"process_step\", values=\"visits\")\n",
    "                  .fillna(0))\n",
    "if \"start\" in conv.columns and \"confirm\" in conv.columns:\n",
    "    conv[\"conversion_rate\"] = 100 * conv[\"confirm\"] / conv[\"start\"]\n",
    "    print(conv[[\"start\",\"confirm\",\"conversion_rate\"]].round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3849eefa-389f-47a2-a6de-443c51b77110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare left (Control) and right (Test) data\n",
    "plot_df = funnel_df.pivot(index=\"process_step\", columns=\"Variation\", values=\"visits\").reindex(steps)\n",
    "control = plot_df.get(\"Control\", pd.Series(0, index=steps)).fillna(0)\n",
    "test    = plot_df.get(\"Test\",    pd.Series(0, index=steps)).fillna(0)\n",
    "\n",
    "# Scale bars to look like funnels (relative to start of each side)\n",
    "def scale_for_funnel(series):\n",
    "    maxv = series.max() if series.max() > 0 else 1\n",
    "    return series / maxv\n",
    "\n",
    "ctrl_scaled = scale_for_funnel(control)\n",
    "test_scaled = scale_for_funnel(test)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "y = np.arange(len(steps))[::-1]  # top = start\n",
    "bar_height = 0.35\n",
    "\n",
    "# Left (Control): draw to the left using negative widths\n",
    "ax.barh(y - bar_height/2, -ctrl_scaled.values, height=bar_height, align=\"center\")\n",
    "# Right (Test)\n",
    "ax.barh(y + bar_height/2,  test_scaled.values, height=bar_height, align=\"center\")\n",
    "\n",
    "# Annotations: actual counts\n",
    "for i, s in enumerate(steps[::-1]):\n",
    "    # Control value on the left\n",
    "    ax.text(-ctrl_scaled.iloc[::-1].values[i] - 0.02, y[i] - bar_height/2,\n",
    "            f\"{int(control.iloc[::-1].values[i])}\", va=\"center\", ha=\"right\", fontsize=9)\n",
    "    # Test value on the right\n",
    "    ax.text( test_scaled.iloc[::-1].values[i] + 0.02, y[i] + bar_height/2,\n",
    "            f\"{int(test.iloc[::-1].values[i])}\", va=\"center\", ha=\"left\", fontsize=9)\n",
    "\n",
    "# Center step labels\n",
    "ax.set_yticks(y)\n",
    "ax.set_yticklabels(steps[::-1])\n",
    "ax.set_xlabel(\"Relative width (scaled)\")\n",
    "ax.set_title(\"Funnel ‚Äì Unique visits reaching each step (Control vs Test)\")\n",
    "\n",
    "# Center divider\n",
    "ax.axvline(0, color=\"black\", linewidth=1)\n",
    "\n",
    "# Legends (simple text)\n",
    "ax.text(-1.0, y[0] + 0.6, \"Control\", fontsize=10, ha=\"left\")\n",
    "ax.text( 0.8, y[0] + 0.6, \"Test\",    fontsize=10, ha=\"right\")\n",
    "\n",
    "# Tidy limits\n",
    "ax.set_xlim(-1.05, 1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb487c18-4e67-457e-888b-4bb041cb51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time between steps per visit\n",
    "df_exp = df_exp.sort_values([\"visit_id\",\"date_time\"]).copy()\n",
    "df_exp[\"time_diff\"] = df_exp.groupby(\"visit_id\")[\"date_time\"].diff()\n",
    "df_exp[\"time_diff_sec\"] = df_exp[\"time_diff\"].dt.total_seconds()\n",
    "\n",
    "mean_time = (df_exp.groupby([\"Variation\",\"process_step\"])[\"time_diff_sec\"]\n",
    "                   .mean()\n",
    "                   .reset_index())\n",
    "\n",
    "# Bar chart\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "# Order steps on x\n",
    "xticks = steps\n",
    "for i, var in enumerate([\"Control\",\"Test\"]):\n",
    "    sub = mean_time[mean_time[\"Variation\"]==var].set_index(\"process_step\").reindex(xticks)\n",
    "    x = np.arange(len(xticks)) + (i-0.5)*0.35\n",
    "    ax.bar(x, sub[\"time_diff_sec\"].values, width=0.35, label=var)\n",
    "\n",
    "ax.set_xticks(np.arange(len(xticks)))\n",
    "ax.set_xticklabels(xticks, rotation=0)\n",
    "ax.set_ylabel(\"Mean time (seconds)\")\n",
    "ax.set_title(\"Mean time between steps ‚Äì Control vs Test\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cee03fb-4920-420f-9941-a361101b88dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_completion / 60)  # mean in minutes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b428456a-bd24-42f9-a251-ff1c832e3e41",
   "metadata": {},
   "source": [
    "##### üéØ Funnel Analysis ‚Äì Control vs Test  \n",
    "\n",
    "We analyzed client progression through each step of the online process.  \n",
    "\n",
    "### Step-by-Step Funnel (Number of Clients)  \n",
    "| Step       | Control | Test   |\n",
    "|------------|---------|--------|\n",
    "| Start      | 30,842  | 33,109 |\n",
    "| Step 1     | 23,486  | 28,238 |\n",
    "| Step 2     | 20,077  | 24,464 |\n",
    "| Step 3     | 18,242  | 22,149 |\n",
    "| Confirm    | 15,988  | 21,692 |\n",
    "\n",
    "### Conversion Rate (Start ‚Üí Confirm)  \n",
    "- **Control:** 51.8%  \n",
    "- **Test:** 65.5%  \n",
    "\n",
    "### Completion Time (Start ‚Üí Confirm, in minutes)  \n",
    "- **Control:** 6.56 min (~394 sec)  \n",
    "- **Test:** 6.04 min (~362 sec)  \n",
    "\n",
    "---\n",
    "\n",
    "### Insights  \n",
    "- ‚úÖ **Higher retention at every step:** The Test group consistently has more clients advancing to each step, showing improved engagement throughout the funnel.  \n",
    "- üìà **Stronger overall conversion:** The redesigned interface increased completion rates by ~14 percentage points (from 52% ‚Üí 66%).  \n",
    "- ‚è± **Faster process:** Test clients complete the entire flow ~32 seconds faster on average, reinforcing that the redesign improves efficiency.  \n",
    "- ‚öñÔ∏è **Balanced trade-off:** Although Test takes slightly longer at *Step 2*, they make up for it by retaining significantly more users to the final confirmation.  \n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion  \n",
    "The funnel analysis demonstrates that the redesigned interface:  \n",
    "- Improves **user retention** across all steps.  \n",
    "- Achieves a **higher overall conversion rate**.  \n",
    "- Delivers **faster completion times**.  \n",
    "\n",
    "Together, these results suggest that the Test variation offers a **more effective and user-friendly process**, with clear business impact.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f1a030-13cd-4cad-af04-b460755af7a3",
   "metadata": {},
   "source": [
    "## üìä Two-Sample T-Test for Completion Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ab34b9-8cf6-4871-b4c7-5095e2e5329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Work only with experiment participants\n",
    "df_exp = df_full[df_full[\"Variation\"].isin([\"Control\",\"Test\"])].copy()\n",
    "df_exp[\"date_time\"] = pd.to_datetime(df_exp[\"date_time\"])\n",
    "df_exp = df_exp.sort_values([\"visit_id\",\"date_time\"])\n",
    "\n",
    "# Get duration Start -> Confirm per visit\n",
    "visit_times = (\n",
    "    df_exp.groupby([\"Variation\",\"visit_id\"])\n",
    "    .agg(start=(\"date_time\",\"first\"), end=(\"date_time\",\"last\"))\n",
    "    .reset_index()\n",
    ")\n",
    "visit_times[\"completion_time\"] = (visit_times[\"end\"] - visit_times[\"start\"]).dt.total_seconds()\n",
    "\n",
    "# Keep only visits that actually reached \"confirm\"\n",
    "completed_visits = df_exp[df_exp[\"process_step\"].str.lower()==\"confirm\"][\"visit_id\"].unique()\n",
    "visit_times = visit_times[visit_times[\"visit_id\"].isin(completed_visits)]\n",
    "\n",
    "# Separate by group\n",
    "control_times = visit_times.loc[visit_times[\"Variation\"]==\"Control\",\"completion_time\"]\n",
    "test_times = visit_times.loc[visit_times[\"Variation\"]==\"Test\",\"completion_time\"]\n",
    "\n",
    "# Two-sample t-test\n",
    "t_stat, p_val = stats.ttest_ind(test_times, control_times, equal_var=False)\n",
    "\n",
    "print(\"Mean Completion Time (Control):\", control_times.mean()/60, \"minutes\")\n",
    "print(\"Mean Completion Time (Test):\", test_times.mean()/60, \"minutes\")\n",
    "print(\"t-statistic:\", t_stat, \"p-value:\", p_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf29950-2bbe-411b-b710-d6deaa8e65ae",
   "metadata": {},
   "source": [
    "## Two-Sample T-Test for Completion Times\n",
    "\n",
    "We conducted a two-sample t-test to evaluate whether the new interface (Test group) led to a statistically significant reduction in mean completion times compared to the traditional interface (Control group).\n",
    "\n",
    "**Hypotheses**  \n",
    "- **H‚ÇÄ (Null):** There is no difference in mean completion time between Control and Test groups.  \n",
    "- **H‚ÇÅ (Alternative):** The Test group has a significantly different mean completion time compared to Control.  \n",
    "\n",
    "**Results**  \n",
    "- Mean Completion Time (Control): **6.57 minutes**  \n",
    "- Mean Completion Time (Test): **6.04 minutes**  \n",
    "- t-statistic: **-5.96**  \n",
    "- p-value: **2.53e-09**\n",
    "\n",
    "**Interpretation**  \n",
    "Since the p-value is far below 0.05, we reject the null hypothesis (**H‚ÇÄ**) and accept the alternative hypothesis (**H‚ÇÅ**).  \n",
    "This confirms that the difference in mean completion time between the Control and Test groups is **statistically significant**.  \n",
    "\n",
    "**Conclusion**  \n",
    "Users in the Test group complete the process faster than those in the Control group.  \n",
    "The redesigned interface improves overall efficiency, reducing completion time by approximately **0.5 minutes per user**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54178e17-4b23-4674-91bd-551be937756c",
   "metadata": {},
   "source": [
    "## Balance Analysis: Do Clients with Higher Balances Interact More and Make Fewer Errors?  \n",
    "\n",
    "### Objective  \n",
    "In this section, we investigate whether clients with larger account balances behave differently during the digital process.  \n",
    "Specifically, we want to determine if:  \n",
    "1. Clients with higher balances **interact more** (i.e., complete more steps/visits).  \n",
    "2. Clients with higher balances are **more careful** (i.e., make fewer backward navigation errors).  \n",
    "\n",
    "### Hypotheses  \n",
    "\n",
    "- **H‚ÇÄ (Null Hypothesis):**  \n",
    "  Account balance has no relationship with client interactions or error rates.  \n",
    "\n",
    "- **H‚ÇÅ (Alternative Hypothesis):**  \n",
    "  Clients with higher balances complete more steps and commit fewer errors.  \n",
    "\n",
    "### Approach  \n",
    "- **Interaction** will be measured by the number of unique steps completed per client.  \n",
    "- **Errors** will be measured as backward navigation (cases where a client goes back to a previous step).  \n",
    "- Both metrics will be compared against account balances using correlations and visualizations.  \n",
    "\n",
    "This analysis will help us understand if wealthier clients tend to engage more carefully with the process, which could influence the overall interpretation of the A/B test results.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3083c48f-2459-470b-be33-3db18cb76851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work only with experiment participants\n",
    "df_exp = df_full[df_full[\"Variation\"].isin([\"Control\", \"Test\"])].copy()\n",
    "\n",
    "# Calculate interactions: number of steps completed per client\n",
    "interactions = (\n",
    "    df_exp.groupby(\"client_id\")[\"process_step\"]\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"process_step\": \"n_steps\"})\n",
    ")\n",
    "\n",
    "# Calculate errors: backward navigation (if step order decreases)\n",
    "df_exp = df_exp.sort_values([\"client_id\", \"visit_id\", \"date_time\"])\n",
    "df_exp[\"step_order\"] = df_exp[\"process_step\"].map({\"start\":0,\"step 1\":1,\"step 2\":2,\"step 3\":3,\"confirm\":4})\n",
    "\n",
    "df_exp[\"backward\"] = df_exp.groupby(\"client_id\")[\"step_order\"].diff().lt(0).astype(int)\n",
    "\n",
    "errors = (\n",
    "    df_exp.groupby(\"client_id\")[\"backward\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"backward\":\"n_errors\"})\n",
    ")\n",
    "\n",
    "# Merge with balance\n",
    "balance_analysis = (\n",
    "    df_full[[\"client_id\",\"bal\"]]\n",
    "    .merge(interactions, on=\"client_id\", how=\"left\")\n",
    "    .merge(errors, on=\"client_id\", how=\"left\")\n",
    ")\n",
    "\n",
    "balance_analysis[\"n_errors\"] = balance_analysis[\"n_errors\"].fillna(0)\n",
    "\n",
    "balance_analysis.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b879b164-0fee-4c38-819e-270b7b2efec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correlation\n",
    "print(balance_analysis[[\"bal\",\"n_steps\",\"n_errors\"]].corr())\n",
    "\n",
    "# Visuals\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(data=balance_analysis, x=\"bal\", y=\"n_steps\", alpha=0.3)\n",
    "plt.title(\"Balance vs Number of Steps Completed\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(data=balance_analysis, x=\"bal\", y=\"n_errors\", alpha=0.3, color=\"red\")\n",
    "plt.title(\"Balance vs Number of Errors (Backward Steps)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505ed332-b307-4ce4-a6df-c03fa0e7a602",
   "metadata": {},
   "source": [
    "## Balance Analysis ‚Äì Results  \n",
    "\n",
    "### Correlation Findings  \n",
    "- The correlation between **balance and steps completed** is extremely weak (~0.00005).  \n",
    "- The correlation between **balance and errors** is also very weak (~0.058).  \n",
    "üëâ This means account balances are **not strong predictors** of interaction or error behavior.  \n",
    "\n",
    "### Visual Insights  \n",
    "- **Balance vs. Steps Completed:**  \n",
    "  - Most clients, regardless of balance, either complete all steps (n_steps = 5) or drop off early.  \n",
    "  - Even very high-balance clients are spread across the same step completion levels as lower-balance clients.  \n",
    "  - No clear upward trend indicates that higher balances do **not lead to more completed steps**.  \n",
    "\n",
    "- **Balance vs. Errors (Backward Steps):**  \n",
    "  - The majority of clients, independent of balance, commit **0‚Äì1 errors**.  \n",
    "  - Some outliers exist (clients with multiple backward steps), but they are not concentrated among high-balance clients.  \n",
    "  - This suggests that **wealthier clients are not necessarily more careful** in avoiding mistakes.  \n",
    "\n",
    "### Interpretation  \n",
    "- **Hypotheses check:**  \n",
    "  - **H‚ÇÄ (Null Hypothesis)** cannot be rejected.  \n",
    "  - There is **no meaningful relationship** between client balances and how carefully or thoroughly clients interact with the process.  \n",
    "\n",
    "- **Business implication:**  \n",
    "  - Interaction quality and error rates appear to depend on **other factors** (e.g., age, tenure, or UI design) rather than financial wealth.  \n",
    "  - This reinforces that the A/B test differences between Control and Test are likely due to the interface changes, not balance-driven behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e042a6a-5953-4f22-a5ac-398796116649",
   "metadata": {},
   "source": [
    "## Error Distribution Analysis  \n",
    "\n",
    "### Objective  \n",
    "After exploring correlations, we now investigate how errors are distributed across clients with different account balances.  \n",
    "Instead of looking only at linear relationships, we will analyze whether clients with **higher balances** systematically make fewer errors compared to clients with **lower balances**.  \n",
    "\n",
    "### Approach  \n",
    "- Split clients into groups based on account balance (e.g., quartiles).  \n",
    "- Compare the **average number of errors** across these groups.  \n",
    "- Visualize the error distribution using boxplots or histograms.  \n",
    "\n",
    "### Hypotheses  \n",
    "- **H‚ÇÄ (Null Hypothesis):**  \n",
    "  There is no difference in error distributions across clients with different balances.  \n",
    "\n",
    "- **H‚ÇÅ (Alternative Hypothesis):**  \n",
    "  Clients with higher balances make fewer errors than those with lower balances.  \n",
    "\n",
    "This analysis will help us understand whether errors are concentrated in specific balance groups or evenly spread across all clients.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b092c4-b3de-4476-a1a4-269c37fb6dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Copy dataframe to avoid modifying original\n",
    "df_quartiles = balance_analysis.copy()\n",
    "\n",
    "# 1. Create balance groups (quartiles)\n",
    "df_quartiles[\"balance_group\"] = pd.qcut(\n",
    "    df_quartiles[\"bal\"], \n",
    "    4, \n",
    "    labels=[\"Low\", \"Mid-Low\", \"Mid-High\", \"High\"]\n",
    ")\n",
    "\n",
    "# 2. Calculate average errors per group\n",
    "error_summary = df_quartiles.groupby(\"balance_group\", observed=False)[\"n_errors\"].mean()\n",
    "\n",
    "print(\"Average number of errors by balance group:\")\n",
    "print(error_summary)\n",
    "\n",
    "# 3. Boxplot visualization\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(\n",
    "    data=df_quartiles, \n",
    "    x=\"balance_group\", \n",
    "    y=\"n_errors\", \n",
    "    hue=\"balance_group\", \n",
    "    palette=\"Set2\", \n",
    "    legend=False\n",
    ")\n",
    "\n",
    "plt.title(\"Error Distribution Across Balance Groups\")\n",
    "plt.xlabel(\"Balance Group\")\n",
    "plt.ylabel(\"Number of Errors\")\n",
    "plt.show()\n",
    "\n",
    "# 4. Histogram (optional, to see distribution overlap)\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(data=df_quartiles, x=\"n_errors\", hue=\"balance_group\", multiple=\"stack\", bins=20)\n",
    "plt.title(\"Error Frequency by Balance Group\")\n",
    "plt.xlabel(\"Number of Errors\")\n",
    "plt.ylabel(\"Count of Clients\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e42ec8-63fc-41fa-acf8-e6d8dbc4bf02",
   "metadata": {},
   "source": [
    "## Error Distribution Analysis Across Balance Groups  \n",
    "\n",
    "### Objective  \n",
    "In this section, we analyze whether clients with **different account balances** show meaningful differences in the **number of errors** (backward steps) made during the process.  \n",
    "\n",
    "### Results  \n",
    "- **Average Errors by Balance Group:**  \n",
    "  - Low Balance: ~0.09 errors  \n",
    "  - Mid-Low Balance: ~0.14 errors  \n",
    "  - Mid-High Balance: ~0.16 errors  \n",
    "  - High Balance: ~0.20 errors  \n",
    "\n",
    "- **Visual Findings:**  \n",
    "  - Most clients, regardless of balance, made **0 errors**, as shown in the frequency distribution.  \n",
    "  - Clients in higher balance groups show a **slightly higher average number of errors**, but the increase is modest.  \n",
    "  - Boxplots indicate a wider spread of errors in higher balance groups, with some clients committing up to 6 backward steps.  \n",
    "\n",
    "### Interpretation  \n",
    "- Contrary to the initial hypothesis, **higher balances do not clearly lead to fewer errors**.  \n",
    "- In fact, wealthier clients appear to make **slightly more backward steps**, suggesting that higher engagement with the process (possibly due to higher stakes or more careful review) may lead to more corrections rather than fewer mistakes.  \n",
    "- The effect, however, is small in magnitude ‚Äî most clients across all balance groups show no errors at all.  \n",
    "\n",
    "### Next Steps  \n",
    "To validate whether the differences are statistically significant, we can run:  \n",
    "1. **ANOVA or Kruskal-Wallis Test** to compare error distributions across balance quartiles.  \n",
    "2. Post-hoc tests if significance is found, to identify which groups differ.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c255ae4-8a8f-42b5-ad6b-404e591e28c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# ANOVA test (parametric)\n",
    "anova_result = stats.f_oneway(\n",
    "    df_quartiles[df_quartiles[\"balance_group\"]==\"Low\"][\"n_errors\"],\n",
    "    df_quartiles[df_quartiles[\"balance_group\"]==\"Mid-Low\"][\"n_errors\"],\n",
    "    df_quartiles[df_quartiles[\"balance_group\"]==\"Mid-High\"][\"n_errors\"],\n",
    "    df_quartiles[df_quartiles[\"balance_group\"]==\"High\"][\"n_errors\"]\n",
    ")\n",
    "\n",
    "print(\"ANOVA Test:\")\n",
    "print(\"F-statistic:\", anova_result.statistic)\n",
    "print(\"p-value:\", anova_result.pvalue)\n",
    "\n",
    "# Kruskal-Wallis test (non-parametric)\n",
    "kruskal_result = stats.kruskal(\n",
    "    df_quartiles[df_quartiles[\"balance_group\"]==\"Low\"][\"n_errors\"],\n",
    "    df_quartiles[df_quartiles[\"balance_group\"]==\"Mid-Low\"][\"n_errors\"],\n",
    "    df_quartiles[df_quartiles[\"balance_group\"]==\"Mid-High\"][\"n_errors\"],\n",
    "    df_quartiles[df_quartiles[\"balance_group\"]==\"High\"][\"n_errors\"]\n",
    ")\n",
    "\n",
    "print(\"\\nKruskal-Wallis Test:\")\n",
    "print(\"H-statistic:\", kruskal_result.statistic)\n",
    "print(\"p-value:\", kruskal_result.pvalue)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00190477-36f3-4b11-9939-b5691ca70dac",
   "metadata": {},
   "source": [
    "## Statistical Test: Do Error Rates Differ by Balance Group?\n",
    "\n",
    "### Objective  \n",
    "We tested whether the average number of navigation errors (backward steps) differs significantly across balance groups (Low, Mid-Low, Mid-High, High).\n",
    "\n",
    "### Methods  \n",
    "- **ANOVA Test (parametric):** Compares means assuming normally distributed errors.  \n",
    "- **Kruskal-Wallis Test (non-parametric):** Compares medians/distributions without assuming normality (more robust for skewed/error data).  \n",
    "\n",
    "### Results  \n",
    "- **ANOVA Test:**  \n",
    "  - F-statistic ‚âà 1402.27  \n",
    "  - p-value = 0.0  \n",
    "- **Kruskal-Wallis Test:**  \n",
    "  - H-statistic ‚âà 3782.06  \n",
    "  - p-value = 0.0  \n",
    "\n",
    "üëâ Both tests strongly reject the **Null Hypothesis (H‚ÇÄ)** that error rates are the same across all balance groups.  \n",
    "\n",
    "### Interpretation  \n",
    "- The differences in error rates between balance groups are **statistically significant**.  \n",
    "- Clients with higher balances actually tend to make **more errors on average**, contradicting the initial expectation that wealthier clients would be more careful.  \n",
    "- This suggests that higher-balance clients may be more **cautious and engaged**, leading to more frequent backtracking in the process.  \n",
    "\n",
    "### Next Step  \n",
    "- Conduct **post-hoc tests** (e.g., Tukey‚Äôs HSD or pairwise Mann-Whitney tests) to determine **which specific balance groups differ** from each other.  \n",
    "- This will clarify whether the increase in errors is progressive with balance or concentrated between specific segments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493fd56e-0cd7-4b30-bbbb-607a63f221ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
